"""
å®Œæ•´çš„ç³»ç»Ÿæµ‹è¯•è„šæœ¬
éªŒè¯æ‰€æœ‰æ¨¡å—çš„åŠŸèƒ½
"""

import sys
import traceback
import numpy as np
from pathlib import Path


def test_imports():
    """æµ‹è¯•æ‰€æœ‰å¯¼å…¥"""
    print("\n" + "="*60)
    print("æµ‹è¯•1: æ¨¡å—å¯¼å…¥")
    print("="*60)
    
    tests = [
        ("numpy", lambda: __import__('numpy')),
        ("torch", lambda: __import__('torch')),
        ("cv2", lambda: __import__('cv2')),
        ("matplotlib", lambda: __import__('matplotlib')),
        ("bitonic_filter", lambda: __import__('bitonic_filter')),
        ("models", lambda: __import__('models')),
        ("preprocessor", lambda: __import__('preprocessor')),
        ("trainer", lambda: __import__('trainer')),
        ("inference", lambda: __import__('inference')),
    ]
    
    passed = 0
    for name, import_func in tests:
        try:
            import_func()
            print(f"  âœ“ {name}")
            passed += 1
        except Exception as e:
            print(f"  âœ— {name}: {e}")
    
    return passed, len(tests)


def test_bitonic_filter():
    """æµ‹è¯•åŒè°ƒæ»¤æ³¢å™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•2: åŒè°ƒæ»¤æ³¢å™¨")
    print("="*60)
    
    from bitonic_filter import BitonicFilter
    
    try:
        # åˆ›å»ºæ»¤æ³¢å™¨
        bf = BitonicFilter(kernel_size=3, alpha=0.5, beta=0.5)
        
        # åˆ›å»ºæµ‹è¯•å›¾åƒ
        image = np.random.rand(64, 64).astype(np.float32)
        
        # åº”ç”¨æ»¤æ³¢
        filtered = bf.apply(image)
        
        assert filtered.shape == image.shape, "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"
        assert filtered.min() >= 0 and filtered.max() <= 1, "è¾“å‡ºèŒƒå›´è¶…å‡º[0,1]"
        
        print("  âœ“ BitonicFilteråˆå§‹åŒ–")
        print("  âœ“ å•é€šé“å»å™ª")
        
        # æµ‹è¯•å½©è‰²å›¾åƒ
        image_rgb = np.random.rand(64, 64, 3).astype(np.float32)
        filtered_rgb = bf.apply(image_rgb)
        assert filtered_rgb.shape == image_rgb.shape, "RGBè¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"
        
        print("  âœ“ å½©è‰²å›¾åƒå¤„ç†")
        
        # æµ‹è¯•å‚æ•°é¢„æµ‹
        params = np.array([0.7, 0.6])
        filtered_with_params = bf.apply(image, params)
        
        print("  âœ“ å‚æ•°åŒ–æ»¤æ³¢")
        
        return 4, 4
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 4


def test_preprocessor():
    """æµ‹è¯•é¢„å¤„ç†æ¨¡å—"""
    print("\n" + "="*60)
    print("æµ‹è¯•3: å›¾åƒé¢„å¤„ç†")
    print("="*60)
    
    from preprocessor import ImagePreprocessor
    
    try:
        preprocessor = ImagePreprocessor(block_size=32)
        
        # å½’ä¸€åŒ–æµ‹è¯•
        image_uint8 = (np.random.rand(128, 128) * 255).astype(np.uint8)
        normalized = preprocessor.normalize(image_uint8)
        assert normalized.dtype == np.float32, "å½’ä¸€åŒ–ç±»å‹é”™è¯¯"
        assert normalized.min() >= 0 and normalized.max() <= 1, "å½’ä¸€åŒ–èŒƒå›´é”™è¯¯"
        print("  âœ“ å›¾åƒå½’ä¸€åŒ–")
        
        # åå½’ä¸€åŒ–æµ‹è¯•
        denormalized = preprocessor.denormalize(normalized)
        assert denormalized.dtype == np.uint8, "åå½’ä¸€åŒ–ç±»å‹é”™è¯¯"
        assert denormalized.min() >= 0 and denormalized.max() <= 255, "åå½’ä¸€åŒ–èŒƒå›´é”™è¯¯"
        print("  âœ“ å›¾åƒåå½’ä¸€åŒ–")
        
        # åˆ†å—æµ‹è¯•
        image = np.random.rand(256, 256).astype(np.float32)
        blocks, positions = preprocessor.split_into_blocks(image)
        assert len(blocks) > 0, "åˆ†å—æ•°é‡ä¸º0"
        assert all(b.shape == (32, 32) for b in blocks), "å—å¤§å°ä¸æ­£ç¡®"
        print(f"  âœ“ å›¾åƒåˆ†å— ({len(blocks)} ä¸ªå—)")
        
        # åˆå¹¶æµ‹è¯•
        merged = preprocessor.merge_blocks(blocks, positions, image.shape[:2])
        assert merged.shape == image.shape, "åˆå¹¶åå½¢çŠ¶ä¸åŒ¹é…"
        mse = np.mean((merged - image) ** 2)
        print(f"  âœ“ å—åˆå¹¶ (MSE: {mse:.2e})")
        
        # å™ªå£°æ·»åŠ æµ‹è¯•
        clean = np.ones((128, 128), dtype=np.float32) * 0.5
        noisy = preprocessor.add_gaussian_noise(clean, sigma=0.1)
        noise_level = np.std(noisy - clean)
        assert 0.08 < noise_level < 0.12, "å™ªå£°æ°´å¹³ä¸ç¬¦åˆé¢„æœŸ"
        print(f"  âœ“ é«˜æ–¯å™ªå£°æ·»åŠ  (Ïƒ={noise_level:.4f})")
        
        # å¡«å……æµ‹è¯•
        image = np.random.rand(100, 100).astype(np.float32)
        padded, (pad_h, pad_w) = preprocessor.pad_image(image)
        unpadded = preprocessor.unpad_image(padded, pad_h, pad_w)
        assert unpadded.shape == image.shape, "å¡«å……/å»å¡«å……å¤±è´¥"
        print("  âœ“ å›¾åƒå¡«å……å¤„ç†")
        
        return 6, 6
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 6


def test_models():
    """æµ‹è¯•æ¨¡å‹"""
    print("\n" + "="*60)
    print("æµ‹è¯•4: CNNæ¨¡å‹")
    print("="*60)
    
    try:
        import torch
        from models import create_model, FeatureExtractor, ParameterPredictor
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"  ä½¿ç”¨è®¾å¤‡: {device}")
        
        # åˆ›å»ºæ¨¡å‹
        model = create_model(in_channels=1, num_features=64, num_params=2, device=device)
        print("  âœ“ æ¨¡å‹åˆ›å»º")
        
        # å‰å‘ä¼ æ’­æµ‹è¯•
        input_tensor = torch.randn(1, 1, 32, 32, device=device)
        with torch.no_grad():
            features, params = model(input_tensor)
        
        assert features.shape == (1, 64), f"ç‰¹å¾å½¢çŠ¶é”™è¯¯: {features.shape}"
        assert params.shape == (1, 2), f"å‚æ•°å½¢çŠ¶é”™è¯¯: {params.shape}"
        assert params.min() >= 0 and params.max() <= 1, "å‚æ•°èŒƒå›´é”™è¯¯"
        print("  âœ“ å‰å‘ä¼ æ’­")
        
        # å‚æ•°ç»Ÿè®¡
        total_params = sum(p.numel() for p in model.parameters())
        print(f"  âœ“ æ¨¡å‹å‚æ•°: {total_params:,}")
        
        # æ¢¯åº¦æµ‹è¯•
        input_tensor.requires_grad = True
        features, params = model(input_tensor)
        loss = features.mean() + params.mean()
        loss.backward()
        print("  âœ“ æ¢¯åº¦è®¡ç®—")
        
        return 4, 4
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 4


def test_trainer():
    """æµ‹è¯•è®­ç»ƒå™¨"""
    print("\n" + "="*60)
    print("æµ‹è¯•5: è®­ç»ƒå™¨")
    print("="*60)
    
    try:
        import torch
        from models import create_model
        from trainer import DenoisingTrainer
        from preprocessor import ImagePreprocessor
        from inference import create_sample_image
        
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # åˆ›å»ºå°è§„æ¨¡æ•°æ®
        clean = create_sample_image((128, 128), 'gradient')
        preprocessor = ImagePreprocessor()
        noisy = preprocessor.add_gaussian_noise(clean, sigma=0.15)
        
        # åˆ›å»ºè®­ç»ƒå™¨
        model = create_model(device=device)
        trainer = DenoisingTrainer(model, device=device)
        print("  âœ“ è®­ç»ƒå™¨åˆ›å»º")
        
        # è®­ç»ƒæ­¥éª¤
        result = trainer.train_step(noisy, clean)
        assert 'loss' in result, "ç¼ºå°‘loss"
        assert 'psnr' in result, "ç¼ºå°‘psnr"
        assert 'ssim' in result, "ç¼ºå°‘ssim"
        print(f"  âœ“ è®­ç»ƒæ­¥éª¤ (Loss: {result['loss']:.4f})")
        
        # éªŒè¯æ­¥éª¤
        result = trainer.validate(noisy, clean)
        assert 'loss' in result, "ç¼ºå°‘éªŒè¯loss"
        print(f"  âœ“ éªŒè¯æ­¥éª¤ (PSNR: {result['psnr']:.2f})")
        
        # æ¨¡å‹ä¿å­˜/åŠ è½½
        trainer.save_model('/tmp/test_model.pth')
        trainer.load_model('/tmp/test_model.pth')
        print("  âœ“ æ¨¡å‹ä¿å­˜å’ŒåŠ è½½")
        
        return 4, 4
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 4


def test_inference():
    """æµ‹è¯•æ¨ç†ç®¡é“"""
    print("\n" + "="*60)
    print("æµ‹è¯•6: æ¨ç†ç®¡é“")
    print("="*60)
    
    try:
        import numpy as np
        from inference import DenoisingPipeline, create_sample_image
        from preprocessor import ImagePreprocessor
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        clean = create_sample_image((128, 128), 'checkerboard')
        preprocessor = ImagePreprocessor()
        noisy = preprocessor.add_gaussian_noise(clean, sigma=0.15)
        
        # åˆ›å»ºç®¡é“
        pipeline = DenoisingPipeline(device='cpu')
        print("  âœ“ æ¨ç†ç®¡é“åˆ›å»º")
        
        # å»å™ª
        denoised = pipeline.denoise(noisy, normalize=False)
        assert denoised.shape == noisy.shape, "è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…"
        assert denoised.min() >= 0 and denoised.max() <= 1, "è¾“å‡ºèŒƒå›´é”™è¯¯"
        print("  âœ“ å›¾åƒå»å™ª")
        
        # è´¨é‡è¯„ä¼°
        mse = np.mean((denoised - clean) ** 2)
        psnr = 10 * np.log10(1.0 / mse) if mse > 0 else 100
        print(f"  âœ“ æ€§èƒ½æŒ‡æ ‡ (PSNR: {psnr:.2f} dB)")
        
        return 3, 3
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 3


def test_integration():
    """é›†æˆæµ‹è¯•"""
    print("\n" + "="*60)
    print("æµ‹è¯•7: ç«¯åˆ°ç«¯é›†æˆ")
    print("="*60)
    
    try:
        import torch
        from models import create_model
        from trainer import DenoisingTrainer
        from preprocessor import ImagePreprocessor, create_noisy_clean_pairs
        from inference import create_sample_image
        
        # åˆ›å»ºå°æ•°æ®é›†
        clean_images = [
            create_sample_image((64, 64), 'gradient'),
            create_sample_image((64, 64), 'circles'),
        ]
        
        dataset = create_noisy_clean_pairs(clean_images, noise_sigma=0.15, num_noise_levels=1)
        print(f"  âœ“ æ•°æ®é›†åˆ›å»º ({len(dataset)} ä¸ªæ ·æœ¬)")
        
        # è®­ç»ƒå¤šä¸ªæ­¥éª¤
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        model = create_model(device=device)
        trainer = DenoisingTrainer(model, device=device)
        
        losses = []
        for noisy, clean in dataset:
            result = trainer.train_step(noisy, clean)
            losses.append(result['loss'])
        
        print(f"  âœ“ å¤šæ­¥éª¤è®­ç»ƒ (å¹³å‡æŸå¤±: {np.mean(losses):.4f})")
        
        # éªŒè¯æ•´ä¸ªæ•°æ®é›†
        val_losses = []
        for noisy, clean in dataset:
            result = trainer.validate(noisy, clean)
            val_losses.append(result['psnr'])
        
        avg_psnr = np.mean(val_losses)
        print(f"  âœ“ æ•°æ®é›†éªŒè¯ (å¹³å‡PSNR: {avg_psnr:.2f})")
        
        return 3, 3
        
    except Exception as e:
        print(f"  âœ— é”™è¯¯: {e}")
        traceback.print_exc()
        return 0, 3


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "="*60)
    print("æ·±åº¦å­¦ä¹ å›¾åƒå»å™ªç³»ç»Ÿ - å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("="*60)
    
    tests = [
        ("å¯¼å…¥", test_imports),
        ("åŒè°ƒæ»¤æ³¢", test_bitonic_filter),
        ("é¢„å¤„ç†", test_preprocessor),
        ("CNNæ¨¡å‹", test_models),
        ("è®­ç»ƒå™¨", test_trainer),
        ("æ¨ç†", test_inference),
        ("é›†æˆ", test_integration),
    ]
    
    results = []
    total_passed = 0
    total_tests = 0
    
    for name, test_func in tests:
        try:
            passed, total = test_func()
            results.append((name, passed, total))
            total_passed += passed
            total_tests += total
        except Exception as e:
            print(f"\nâœ— {name}æµ‹è¯•å´©æºƒ: {e}")
            traceback.print_exc()
            results.append((name, 0, 1))
            total_tests += 1
    
    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)
    
    for name, passed, total in results:
        status = "âœ“" if passed == total else "âœ—"
        print(f"{status} {name}: {passed}/{total}")
    
    print("\n" + "-"*60)
    print(f"æ€»è®¡: {total_passed}/{total_tests} ä¸ªæµ‹è¯•é€šè¿‡")
    print("-"*60)
    
    if total_passed == total_tests:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå‡†å¤‡å°±ç»ªã€‚")
        return 0
    else:
        print(f"\nâš ï¸  {total_tests - total_passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šé¢çš„é”™è¯¯ä¿¡æ¯ã€‚")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
